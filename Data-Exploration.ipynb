{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa90f155-b9c1-4f1e-89d5-d1fa63bbb4d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqq langchain_core langchain_databricks langchain_community\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd6987de-71a9-47fb-8aa9-6f2c33a3dc3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM `Dais`.bright_initiative.airbnb_properties_information\n",
    "WHERE\n",
    "  location = 'Chicago, Illinois, United States'\n",
    "  AND host_number_of_reviews > 1000\n",
    "  AND EXISTS(reviews, review -> review ILIKE '%wheelchair%')\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dafc08ff-d375-49b5-b17a-d4e1327ac00d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "\n",
    "# configure workspace tokens\n",
    "w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\")\n",
    "\n",
    "def format_context(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Converts the DataFrame into a JSON string to ensure all data is passed\n",
    "    to the model without truncation. JSON is also a great format for structured data\n",
    "    like you have in 'description_by_sections'.\n",
    "    \"\"\"\n",
    "    return df.to_json(orient='records', indent=2)\n",
    "\n",
    "def find_accessible_airbnb_properties(location: str) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Queries the Bright Initiative Airbnb dataset for properties in a specific location\n",
    "  that have reviews mentioning \"wheelchair\".\n",
    "  \"\"\"\n",
    "  query = f\"\"\"\n",
    "    SELECT\n",
    "      listing_name,\n",
    "      location_details,\n",
    "      location,\n",
    "      details,\n",
    "      description_by_sections,\n",
    "      reviews\n",
    "    FROM `Dais`.bright_initiative.airbnb_properties_information\n",
    "    WHERE\n",
    "      location ILIKE '%{location}%'\n",
    "      AND host_number_of_reviews > 1000\n",
    "      AND EXISTS(reviews, review -> review ILIKE '%wheelchair%')\n",
    "    LIMIT 5\n",
    "  \"\"\"\n",
    "  return format_context(spark.sql(query).toPandas())\n",
    "\n",
    "# Define the prompt template for the LLM\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "  \"\"\"\n",
    "  You are a helpful assistant for accessible travel. Your goal is to summarize potential Airbnb listings for a user.\n",
    "\n",
    "  The following listing *mention* wheelchairs but may not actually be accessible. Closely review the descriptions and review,\n",
    "  and then summarize the accessibility features (or lack thereof).\n",
    "\n",
    "  Here is the JSON data:\n",
    "  {context}\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\")\n",
    "\n",
    "# This is our simple \"agentic\" chain\n",
    "chain = (\n",
    "    find_accessible_airbnb_properties\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Let's run the chain for Chicago!\n",
    "result = chain.invoke(\"Chicago\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9996569c-068a-4364-8fd3-a9a93fcad92a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW medicare_benefits_analysis AS\n",
    "WITH benefit_codes AS (\n",
    "  SELECT array(\n",
    "    '14c10', '14c11', '14c12', '14c13', '14c14', '14c15', '14c16', '14c17', '14c18', '14c19',\n",
    "    '14c20', '14c21', '14c22', '14c8', '14c9', '17a1', '17a2', '17b1', '17b2', '17b3',\n",
    "    '17b4', '17b5', '18a1', '18a2', '18b1', '18b2', '18b3', '18b4', '18c',\n",
    "    '13a', '7b1', '7b2', '16b1', '16b2', '16b3', '16b4', '16b5', '16b6',\n",
    "    '11a1', '11a2', '14c4', '6-1', '6-2', '6-3', '6-4', '13b',\n",
    "    '13i1', '13i2', '13i3', '13i4', '13i5', '13i6', '13i7', '13i8', '13i9', '13i10',\n",
    "    '13i11', '13i12', '13i13', '13i14', '13i15', '10b1', '10b2'\n",
    "  ) AS codes\n",
    "),\n",
    "latest_bids AS (\n",
    "  SELECT *\n",
    "  FROM (\n",
    "    SELECT *,\n",
    "           ROW_NUMBER() OVER (PARTITION BY bid_id ORDER BY version DESC) as rn\n",
    "    FROM `dais-hackathon-2025`.mimilabs.pbp_section_d\n",
    "    WHERE YEAR(mimi_src_file_date) = 2025\n",
    "  )\n",
    "  WHERE rn = 1\n",
    "),\n",
    "processed_bids AS (\n",
    "  SELECT\n",
    "    lb.*,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_1, ''), '\\s+', ''), ';'), x -> x != '') AS clean_cats_1,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_2, ''), '\\s+', ''), ';'), x -> x != '') AS clean_cats_2,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_3, ''), '\\s+', ''), ';'), x -> x != '') AS clean_cats_3,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_4, ''), '\\s+', ''), ';'), x -> x != '') AS clean_cats_4,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_5, ''), '\\s+', ''), ';'), x -> x != '') AS clean_cats_5\n",
    "  FROM latest_bids lb\n",
    "  CROSS JOIN benefit_codes bc\n",
    "  WHERE arrays_overlap(bc.codes,\n",
    "    filter(split(regexp_replace(CONCAT_WS(';',\n",
    "          COALESCE(lb.pbp_d_combo_nmc_cats_1, ''), COALESCE(lb.pbp_d_combo_nmc_cats_2, ''),\n",
    "          COALESCE(lb.pbp_d_combo_nmc_cats_3, ''), COALESCE(lb.pbp_d_combo_nmc_cats_4, ''),\n",
    "          COALESCE(lb.pbp_d_combo_nmc_cats_5, '')), '\\s+', ''), ';'), x -> x != '')\n",
    "  )\n",
    "),\n",
    "final_benefits AS (\n",
    "  SELECT\n",
    "    pb.pbp_a_hnumber,\n",
    "    pb.pbp_a_plan_identifier,\n",
    "    array_distinct(flatten(array(pb.clean_cats_1, pb.clean_cats_2, pb.clean_cats_3, pb.clean_cats_4, pb.clean_cats_5))) AS all_benefits\n",
    "  FROM processed_bids pb\n",
    ")\n",
    "SELECT\n",
    "  pbp_a_hnumber,\n",
    "  pbp_a_plan_identifier,\n",
    "  all_benefits,\n",
    "  arrays_overlap(all_benefits, array('13a')) AS has_acupuncture,\n",
    "  arrays_overlap(all_benefits, array('7b1', '7b2')) AS has_chiropractic,\n",
    "  arrays_overlap(all_benefits, array('16b1', '16b2', '16b3', '16b4', '16b5', '16b6')) AS has_dental,\n",
    "  arrays_overlap(all_benefits, array('11a1', '11a2')) AS has_dme,\n",
    "  arrays_overlap(all_benefits, array('14c4')) AS has_fitness,\n",
    "  arrays_overlap(all_benefits, array('6-1', '6-2', '6-3', '6-4')) AS has_home_health,\n",
    "  arrays_overlap(all_benefits, array('13b', '13i1', '13i2', '13i3', '13i4', '13i5', '13i6', '13i7', '13i8', '13i9', '13i10', '13i11', '13i12', '13i13', '13i14', '13i15')) AS has_otc_ssbci,\n",
    "  arrays_overlap(all_benefits, array('10b1', '10b2')) AS has_transportation\n",
    "FROM final_benefits\n",
    "\"\"\")\n",
    "\n",
    "print(\"Temporary view 'medicare_benefits_analysis' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c86c2a2-25d4-43bd-bdbd-77fc79044ca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "-- Find the first 10 plans that offer fitness benefits\n",
    "SELECT *\n",
    "FROM\n",
    "  medicare_benefits_analysis\n",
    "WHERE\n",
    "  has_fitness = true\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95cf51b7-663a-427d-a682-691f6935b618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from langchain_community.tools import tool\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "import ast\n",
    "\n",
    "@tool\n",
    "def find_plans_with_benefits(required_benefits: str) -> str:\n",
    "  \"\"\"\n",
    "  Finds Medicare Advantage plans that include all of the specified supplemental benefits.\n",
    "  Use this tool when a user asks to find plans with a specific list of benefits.\n",
    "  The input must be a Python list of benefit names provided as a string, chosen from:\n",
    "  'acupuncture', 'chiropractic', 'dental', 'dme', 'fitness', 'home_health', 'otc_ssbci', 'transportation'.\n",
    "  For example: \"['dental', 'fitness']\"\n",
    "  \"\"\"\n",
    "  try:\n",
    "    # The LLM often returns a string representation of a list, e.g., \"['dental', 'fitness']\".\n",
    "    # ast.literal_eval safely evaluates this string into an actual Python list.\n",
    "    benefits_list = ast.literal_eval(required_benefits)\n",
    "    if not isinstance(benefits_list, list):\n",
    "        raise ValueError(\"Input could not be parsed into a list.\")\n",
    "  except (ValueError, SyntaxError) as e:\n",
    "    # If parsing fails, return an error message to the agent so it can retry.\n",
    "    return f\"Error: Invalid input format. Expected a string representation of a list. {e}\"\n",
    "\n",
    "  # Build a WHERE clause from the list of required benefits\n",
    "  where_conditions = [f\"has_{benefit.strip()} = true\" for benefit in benefits_list]\n",
    "  where_clause = \" AND \".join(where_conditions)\n",
    "\n",
    "  query = f\"\"\"\n",
    "    SELECT pbp_a_hnumber, pbp_a_plan_identifier, all_benefits\n",
    "    FROM medicare_benefits_analysis\n",
    "    WHERE {where_clause}\n",
    "    LIMIT 10\n",
    "  \"\"\"\n",
    "  print(f\"Executing query: {query}\") # For debugging\n",
    "  df = spark.sql(query).toPandas()\n",
    "  return df.to_json(orient='records', indent=2)\n",
    "\n",
    "# Configure workspace client for authentication\n",
    "w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "# The LLM is the \"brain\" of the agent\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=2048)\n",
    "\n",
    "# The Agent needs a list of tools it can use\n",
    "tools = [find_plans_with_benefits]\n",
    "\n",
    "# This prompt template tells the agent how to reason about using tools\n",
    "# This is a standard \"ReAct\" (Reasoning + Acting) prompt\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent by combining the LLM, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Let's ask our agent a question in natural language!\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Can you find me some plans that have dental, fitness, and transportation benefits?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Final Answer ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b695caa8-32a5-49a7-b86e-a0b2e3382446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from `dais-hackathon-2025`.nimble.dbx_amazon_serp_daily limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2caf8d5-05c5-4507-afbf-4e94017e9aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.tools import tool\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "\n",
    "\n",
    "@tool\n",
    "def find_products_by_keyword(search_term: str) -> str:\n",
    "  \"\"\"\n",
    "  Searches the Nimble e-commerce dataset for products matching a keyword search_term.\n",
    "  Use this to find products based on a user's request.\n",
    "  The input must be a single string. For example: \"clip on reading light\"\n",
    "  \"\"\"\n",
    "  query = f\"\"\"\n",
    "    SELECT\n",
    "      productId,\n",
    "      product_name,\n",
    "      price,\n",
    "      rating,\n",
    "      review_count,\n",
    "      product_url\n",
    "    FROM `dais-hackathon-2025`.nimble.dbx_amazon_serp_daily\n",
    "    WHERE\n",
    "      product_name ILIKE '%{search_term}%'\n",
    "    LIMIT 5\n",
    "  \"\"\"\n",
    "  print(f\"Executing query: {query}\") # For debugging\n",
    "  df = spark.sql(query).toPandas()\n",
    "  return df.to_json(orient='records', indent=2)\n",
    "\n",
    "  w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "# The LLM is the \"brain\" of the agent\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=2048)\n",
    "\n",
    "# The Agent needs a list of tools it can use\n",
    "tools = [find_products_by_keyword]\n",
    "\n",
    "# This prompt template tells the agent how to reason and use tools\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Your process should be to first think of a few different, specific search terms based on the user's question.\n",
    "Then, use the `find_products_by_keyword` tool for each of those keywords, one at a time.\n",
    "After you have gathered all the product information from your searches, combine the results into a single, helpful summary for the user.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: After you find the products from all your searches, your final answer should summarize them and suggest that a good next step would be to use a web browsing tool to analyze the product pages for more detailed information.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent by combining the LLM, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Let's ask our agent to find a product related to accessibility\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"I'm looking for a tool to help my elderly parent open tight jars.\"\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Final Answer ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d454dd4-3af2-47cb-afdf-c7c825f14ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_community.tools import tool\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# --- set up Databricks auth ---\n",
    "w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(\n",
    "    comment=\"for model serving\", lifetime_seconds=1200\n",
    ").token_value\n",
    "\n",
    "@tool\n",
    "def find_places_by_keyword(search_term: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the Nimble Google Maps dataset for places matching a keyword\n",
    "    across title, offerings, business descriptions, and categories.\n",
    "    Input: a single string, e.g. \"playground wheelchair accessible\"\n",
    "    Returns: up to 5 matching places as JSON.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "      title,\n",
    "      street_address,\n",
    "      city,\n",
    "      country,\n",
    "      latitude,\n",
    "      longitude,\n",
    "      rating,\n",
    "      number_of_reviews,\n",
    "      price_level,\n",
    "      place_information.website_url  AS website_url,\n",
    "      place_information.reviews_link AS reviews_link,\n",
    "      phone_number,\n",
    "      place_url,\n",
    "      business_category_ids,\n",
    "      business_status\n",
    "    FROM (\n",
    "      SELECT\n",
    "        *,\n",
    "        transform(offerings, o -> o.display_name)   AS offering_names,\n",
    "        business_description                       AS descriptions,\n",
    "        business_category_ids                      AS categories\n",
    "      FROM `dais-hackathon-2025`.nimble.dbx_google_maps_search_daily\n",
    "    ) t\n",
    "    WHERE\n",
    "      exists(t.offering_names, x -> x ILIKE '%{search_term}%')\n",
    "      OR exists(t.descriptions,    x -> x ILIKE '%{search_term}%')\n",
    "      OR exists(t.categories,      x -> x ILIKE '%{search_term}%')\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(f\"Executing query: {query}\")  # debug\n",
    "    df = spark.sql(query).toPandas()\n",
    "    return df.to_json(orient='records', indent=2)\n",
    "\n",
    "\n",
    "# --- LLM & tools setup ---\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=2048)\n",
    "tools = [find_places_by_keyword]\n",
    "\n",
    "# --- updated prompt template ---\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following question using your tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Your process should be:\n",
    "1. Think of a few specific search terms for the user's question.\n",
    "2. Call `find_places_by_keyword` for each term individually, as in \"playground\", \"wheelchair accessible\" and relevant combinations.\n",
    "3. Combine all observations into a structured recommendation.\n",
    "\n",
    "Use this format:\n",
    "\n",
    "Question: the input question\n",
    "Thought: your reasoning\n",
    "Action: the tool to call (must be one of [{tool_names}])\n",
    "Action Input: the input string\n",
    "Observation: the tool’s output\n",
    "... (repeat Thought/Action/Action Input/Observation as needed)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: your comprehensive recommendation and next steps\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# --- build and run the agent ---\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Example invocation:\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Find a good accessible playground in San Francisco for toddlers.\"\n",
    "})\n",
    "print(\"\\n\\n--- Final Answer ---\")\n",
    "print(response['output'])\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6818324298817183,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data-Exploration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
